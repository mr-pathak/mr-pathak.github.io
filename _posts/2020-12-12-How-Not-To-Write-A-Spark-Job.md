---
layout: post
category: distributed-systems
title: How Not To Write A Spark Job!
---

# --- up coming blog ---

---
# Content
# Problem Statement
# The ugly code
# Challenges
## 1. Singleton Scylla class
## 2. Counting Sketches
## 3. Reduce By Key
## 4. Persis/Unpersist Parent transforms

---
# References

* [Fake Locally](https://stackoverflow.com/questions/38210703/how-to-run-spark-distributed-in-cluster-mode-but-take-file-locally)
* [Apache Spark - Worker write locally](http://apache-spark-user-list.1001560.n3.nabble.com/writing-to-local-files-on-a-worker-td33950.html#a33953)
* [Over subscribing CPU cores](https://nathan.gs/2020/01/02/spark-oversubscribing-cpu-cores/)
* [Spark Tuning is fun](https://hyperj.net/note.arts/asset/pdf/tuning-apache-spark-resource-usage-for-fun-and-efficiency.pdf)
* [What is sent to worker (jar?)](https://stackoverflow.com/questions/25276409/what-is-a-task-in-spark-how-does-the-spark-worker-execute-the-jar-file/25286412#25286412)
* [Spark task vs Executor cores](https://stackoverflow.com/questions/37545069/what-is-the-difference-between-spark-task-cpus-and-executor-cores)
* [Millions of Records - Adobe uses Spark](https://link.medium.com/50b9uPR9Ebb)
* [Using Kryo To Serialize Tasks and Data objects](https://www.cnblogs.com/fillPv/p/5045928.html)
* [HLL Sketches](https://github.com/google/zetasketch)
* [HL in Spark](https://databricks.com/blog/2019/05/08/advanced-analytics-with-apache-spark.html)
* [Learning Spark](https://www.oreilly.com/library/view/learning-spark/9781449359034/ch04.html)

The easiest way to make your first post is to edit this one. Go into /_posts/ and update the Hello World markdown file. For more instructions head over to the [Jekyll Now repository](https://github.com/barryclark/jekyll-now) on GitHub.
